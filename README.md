# SÃ©rie Temporelle et Spark Streaming

## Introduction

L'objectif de ce projet de groupe est de simuler l'acquisition en streaming de donnÃ©es sur lesquelles seront appliquÃ©s des modÃ¨les prÃ©dictifs.  

Les donnÃ©es proviennent du site [Ãle-de-France MobilitÃ©s](https://data.iledefrance-mobilites.fr/explore/dataset/histo-validations-reseau-ferre/information/?sort=annee).  
Elles contiennent l'historique du nombre de validations de titres de transport chaque jour pour diffÃ©rentes stations et catÃ©gories d'abonnement (ex : Navigo, Imagine R).  

â¡ï¸ Plus de dÃ©tails [ici](https://data.iledefrance-mobilites.fr/api/datasets/1.0/histo-validations-reseau-ferre/attachments/donnees_de_validation_pdf/).  

Nous transformons ces donnÃ©es afin de traiter trois cas diffÃ©rents :
- L'Ã©volution du nombre total de validations par jour.
- L'Ã©volution du nombre total de validations par catÃ©gorie d'abonnement et par jour.
- L'Ã©volution du nombre total de validations par station et par jour.  

Ces transformations sont effectuÃ©es avec Spark Streaming et Ã©crites dans trois dossiers distincts au fur et Ã  mesure, afin de simuler une acquisition de donnÃ©es en temps rÃ©el.  

Ensuite, un modÃ¨le prÃ©dictif utilisant l'historique des 45 derniÃ¨res mesures estime le nombre de validations pour le jour suivant.  
L'objectif est de comparer les valeurs prÃ©dites avec les valeurs rÃ©elles afin de dÃ©tecter d'Ã©ventuelles anomalies.  

---

## Structure du Projet

ğŸ“ **`data/processed`** : DÃ©compressez le fichier `data.rar` pour rÃ©cupÃ©rer des donnÃ©es prÃªtes Ã  l'utilisation.  
ğŸ“ **`modelisation/`** : Contient toute la partie modÃ¨le et monitoring.  
ğŸ“ **`IDFM_Spark/`** : Contient la partie Spark.  

---

## Spark Streaming

ğŸ“œ **`script.scala`**  
Ce script rÃ©cupÃ¨re le fichier de donnÃ©es dans `data/firstCSV/`, le dÃ©compose et le reconstruit progressivement dans `data/csv/`.  
Toutes les 20 secondes, il ajoute 7 nouvelles lignes jusqu'Ã  reconstituer le fichier de donnÃ©es initial.  

ğŸ“œ **`SparkStream.scala`**  
Ce script lit en continu les fichiers dans `data/csv/` avec une fenÃªtre de 1 minute d'intervalle, effectue diffÃ©rentes opÃ©rations de regroupement et Ã©crit les rÃ©sultats dans `data/output/`.  
Il utilise un **watermark** de 1 minute pour mieux gÃ©rer les retards potentiels et Ã©viter les donnÃ©es erronÃ©es.  
ğŸ“Œ [Explication du watermarking](https://www.databricks.com/blog/feature-deep-dive-watermarking-apache-spark-structured-streaming)  

---

## ModÃ¨le PrÃ©dictif

Nous utilisons des **rÃ©seaux de neurones rÃ©currents (RNN)**, particuliÃ¨rement adaptÃ©s Ã  l'analyse des sÃ©ries temporelles.  
Les modÃ¨les sont entraÃ®nÃ©s sur **4 ans d'historique (2015-2019)** et testÃ©s sur l'annÃ©e suivante.  
Nous avons dÃ©libÃ©rÃ©ment exclu les donnÃ©es correspondant Ã  la pandÃ©mie de COVID-19.  

ğŸ–¼ï¸ **Visualisation des rÃ©sultats**  
![model_test](imgs%2Fmodel_test.png)  

- Axe vertical : Nombre total de validations sur tout le rÃ©seau.  
- Axe horizontal : Jours de l'annÃ©e 2019.  
- Les valeurs rÃ©elles et les prÃ©dictions sont superposÃ©es.  

ğŸ“Œ Une prÃ©diction pour le jour *x* nÃ©cessite les **45 derniÃ¨res valeurs**.  
Ainsi, le premier jour affichÃ© correspond au **jour 46**, et les donnÃ©es sont tronquÃ©es au **1er dÃ©cembre**, juste avant la pandÃ©mie.  

â¡ï¸ **PremiÃ¨re observation** : Les prÃ©dictions semblent bien coÃ¯ncider avec les valeurs rÃ©elles, les variations saisonniÃ¨res Ã©tant correctement capturÃ©es.  

ğŸ” **Zoom sur une pÃ©riode de 2 semaines (jours 58 Ã  72)**  
![zoom_model_test](imgs%2Fzoom_model_test.png)  

- Pendant la **premiÃ¨re semaine**, les prÃ©dictions suivent bien les variations rÃ©elles.  
- On observe une hausse prÃ©vue par le modÃ¨le Ã  partir du **lundi suivant**, qui ne s'est pas rÃ©alisÃ©e (probablement un jour fÃ©riÃ©).  
- **Ajout d'un indicateur "jour fÃ©riÃ©"** dans le modÃ¨le : pas d'amÃ©lioration notable.  
ğŸ“Œ **Le modÃ¨le reste perfectible.**  

---

## Monitoring  

L'objectif final est de prÃ©senter un **dashboard rÃ©capitulatif** pour mettre en Ã©vidence les anomalies.  

ğŸ”¢ **Calcul de la diffÃ©rence entre valeurs rÃ©elles et prÃ©dites :**  
- On soustrait la **marge d'erreur moyenne** du modÃ¨le.  
- Cette marge est calculÃ©e en moyennant l'erreur entre valeurs rÃ©elles et prÃ©dites sur le jeu de test, pour chaque jour, type de titre et station.  
âœ… Cela amÃ©liore la **confiance dans la dÃ©tection des anomalies**.  

### ğŸ“… **Exemple du 29 mai 2019 (mercredi - jour ouvrÃ©)**
![monitoring_normalDay](imgs%2Fmonitoring_normalDay.png)  

ğŸ“Š **Graphiques :**  
- **Haut** : Top 5 des plus grandes diffÃ©rences par station.  
- **Bas gauche** : DiffÃ©rence entre le nombre total de validations sur le rÃ©seau.  
- **Bas droit** : Nombre total de validations par type d'abonnement.  

â¡ï¸ **Analyse** :  
Tout semble normal sauf **trois stations** affichant des validations plus faibles que prÃ©vu (travaux ou incidents ?).  

### ğŸ“… **Exemple du 30 mai 2019 (jeudi - jour fÃ©riÃ©)**
![monitoring_closedDay](imgs%2Fmonitoring_closedDay.png)  

â¡ï¸ **Analyse** :  
Les Ã©carts sont **trÃ¨s importants** ! Ã‰tant donnÃ© qu'il s'agit d'un jour fÃ©riÃ©, les valeurs rÃ©elles sont bien **plus basses** que celles prÃ©dites.
